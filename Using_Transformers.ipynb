{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEyY9WB0OlvoE+UiuhVGQp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matonice/30-Days-of-Transformer/blob/main/Using_Transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q07ZJWbwyhch"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install transformers\n",
        "!pip install torch\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preprocessing with tokenizer**"
      ],
      "metadata": {
        "id": "GTdCukoKz6BP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "input_text = \"I really love working with transformers models\"\n",
        "inputs = tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "inputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ymCN3ZyYyv76",
        "outputId": "f60dcb3b-c662-4a8a-dd2b-740d82b378b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': tensor([[  101,  1045,  2428,  2293,  2551,  2007, 19081,  4275,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Passing the inputs into a model**"
      ],
      "metadata": {
        "id": "HlP4-ib337N4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "outputs = model(**inputs)\n",
        "print(outputs.logits.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPk799yO3uS8",
        "outputId": "0e1b5a12-d027-461d-cd3b-d2f47096d115"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**PostProcessing the output**"
      ],
      "metadata": {
        "id": "QoTd7MCb6NxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs.logits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am7wZ2Jl4soG",
        "outputId": "7837c7f7-9f73-462a-a186-35a62d541e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-3.1534,  3.2794]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "predictions = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
        "print(predictions)\n",
        "model.config.id2label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jXaqmpe6ae4",
        "outputId": "d06052b0-c975-412c-8f73-7d594297a18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0016, 0.9984]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'NEGATIVE', 1: 'POSITIVE'}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading a trained transformer model**"
      ],
      "metadata": {
        "id": "XruQpDvn7ztc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "model = BertModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89,
          "referenced_widgets": [
            "bef57250bb0d4c068eacd889c93913c5",
            "8f397803690a4c6a95bb6437c4c5d0e4",
            "924e296cbc9b42d1ad1a192bb9d048f4",
            "d1476bdb0a4c4d27820727ffff718adb",
            "9454b2a9af5443ceb462e71ab9737ebd",
            "681c4e6400df4e9dbba4c990e767c295",
            "a2cded8d629d43ff8474376b830089e8",
            "62567a02a4194c1e848c86fd6d84bf35",
            "f34e1cb6b4a64a9f9ae0b5f815654b4d",
            "c88051700b1a4ec1a61d08d88c03b055",
            "23178b15327441d2bdf47602f2777a7a",
            "36e09b85bcdf4c4cb23af5cdda503421",
            "380532f9c4a44e5ab5008cda924c12b3",
            "d91671df16a24f31a02329cdca992801",
            "093246c008194dc5b89e7ff1028ccbbd",
            "3c0bce47f3334baebd17a9d2ee6f0b53",
            "97ba8e6b351e49178d5b46eedc346345",
            "48ead0388eb245d1b6661a0c5da38e9c",
            "0b724e72d55b46a6a7d16025c4a4c37d",
            "3b60f00b253947f9962d92656ff4cb94",
            "0ed033dbad1047669d3cfb5a6b225eac",
            "9899a0cafd07475182030dd4fe7fe922"
          ]
        },
        "id": "rdE6qGr760DY",
        "outputId": "47873bfe-3d62-476f-ca40-f62c8bdf3310"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bef57250bb0d4c068eacd889c93913c5"
            },
            "application/json": {
              "n": 0,
              "total": 570,
              "elapsed": 0.07171869277954102,
              "ncols": null,
              "nrows": null,
              "prefix": "Downloading config.json",
              "ascii": false,
              "unit": "B",
              "unit_scale": true,
              "rate": null,
              "bar_format": null,
              "postfix": null,
              "unit_divisor": 1024,
              "initial": 0,
              "colour": null
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/416M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36e09b85bcdf4c4cb23af5cdda503421"
            },
            "application/json": {
              "n": 0,
              "total": 435779157,
              "elapsed": 0.07233023643493652,
              "ncols": null,
              "nrows": null,
              "prefix": "Downloading pytorch_model.bin",
              "ascii": false,
              "unit": "B",
              "unit_scale": true,
              "rate": null,
              "bar_format": null,
              "postfix": null,
              "unit_divisor": 1024,
              "initial": 0,
              "colour": null
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving a model**"
      ],
      "metadata": {
        "id": "WNUEbEeH8GGF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained(\"my_first_bert_model\")"
      ],
      "metadata": {
        "id": "uhQoMfVU8EEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading and saving a tokenizer**"
      ],
      "metadata": {
        "id": "vpgiLAfM9nd6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertModel\n",
        "\n",
        "tokenizer = BertModel.from_pretrained(\"bert-base-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEIZ0PC48Oxw",
        "outputId": "9566c446-fbae-4e3e-927d-b8c275cbcfd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"my_first_bert_tokenizer\")"
      ],
      "metadata": {
        "id": "AFQLoeTQ97sE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What happens inside the tokenizer function**"
      ],
      "metadata": {
        "id": "uhFLNUdo-Cn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) tokenization\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "tokens = tokenizer.tokenize(input_text)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ow2jAq8k-A3F",
        "outputId": "c8a9a157-2e84-42b9-c6f1-dd94bc10efce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'really', 'love', 'working', 'with', 'transformers', 'models']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) tokens to ids\n",
        "id = tokenizer.convert_tokens_to_ids(tokens)\n",
        "id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOdebluf-Y-m",
        "outputId": "22632bf6-c516-4a2f-bfb5-afe794171451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1045, 2428, 2293, 2551, 2007, 19081, 4275]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Decoding \n",
        "decoded_string = tokenizer.decode(id)\n",
        "decoded_string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ekfZ0sak_AG8",
        "outputId": "3b0b95b3-787e-456b-9366-1d5bbfde7523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'i really love working with transformers models'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Putting all together**"
      ],
      "metadata": {
        "id": "igPQNJU0AKrG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n",
        "\n",
        "tokens = tokenizer(input_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "output = model(**tokens)"
      ],
      "metadata": {
        "id": "O6ZFlsgx_Or4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8xWa-1CSAXIs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}